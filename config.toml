# GPT-2 model config
# changing these values will require re training the model
# because new weights will be initialized
[model]
n_head = 12
n_embd = 768
d_ff_k = 4
bias = false
dropout = 0.0
n_layer = 12
max_seq_len = 50

# training config, changing these values will adjust the training process
[train]
seed = 8723642934
num_epochs = 1
batch_size = 9
target_batch_size = 36
num_workers = 6
learning_rate = 0.0005
weight_decay = 0.01
warmup_steps = 350
elements_per_epoch = 10000